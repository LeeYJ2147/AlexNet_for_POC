{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0522c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN directory check start\n",
      "\n",
      "TEST directory check start\n",
      "\n",
      "### TRAIN directory\n",
      "  File: train\\Chorionic_villi\\326.jpg | Size: (157, 224)\n",
      "  File: train\\Chorionic_villi\\327.jpg | Size: (157, 224)\n",
      "  File: train\\Chorionic_villi\\328.jpg | Size: (157, 224)\n",
      "  File: train\\Trophoblastic_tissue\\427.jpg | Size: (205, 224)\n",
      "  File: train\\Trophoblastic_tissue\\428.jpg | Size: (205, 224)\n",
      "  File: train\\Trophoblastic_tissue\\429.jpg | Size: (205, 224)\n",
      "  File: train\\Trophoblastic_tissue\\439.jpg | Size: (187, 224)\n",
      "  File: train\\Trophoblastic_tissue\\440.jpg | Size: (187, 224)\n",
      "  File: train\\Trophoblastic_tissue\\441.jpg | Size: (187, 224)\n",
      "  File: train\\Trophoblastic_tissue\\47.jpg | Size: (191, 224)\n",
      "  File: train\\Trophoblastic_tissue\\475.jpg | Size: (208, 224)\n",
      "  File: train\\Trophoblastic_tissue\\476.jpg | Size: (208, 224)\n",
      "  File: train\\Trophoblastic_tissue\\477.jpg | Size: (208, 224)\n",
      "  File: train\\Trophoblastic_tissue\\48.jpg | Size: (191, 224)\n",
      "  File: train\\Trophoblastic_tissue\\530.jpg | Size: (103, 224)\n",
      "  File: train\\Trophoblastic_tissue\\531.jpg | Size: (103, 224)\n",
      "  File: train\\Trophoblastic_tissue\\565.jpg | Size: (155, 224)\n",
      "  File: train\\Trophoblastic_tissue\\566.jpg | Size: (155, 224)\n",
      "\n",
      "### TEST directory\n",
      "  Sizes of all data are (224, 224).\n"
     ]
    }
   ],
   "source": [
    "# Check Image Size\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import datasets\n",
    "\n",
    "root_dirs = ['train', 'test'] \n",
    "classes = [\n",
    "    'Chorionic_villi',\n",
    "    'Decidual_tissue',\n",
    "    'Hemorrhage',\n",
    "    'Trophoblastic_tissue'\n",
    "]\n",
    "\n",
    "# {'train': {'first_size': (W, H), 'inconsistent_images': [...]}, 'test': {...}}\n",
    "results = {}\n",
    "\n",
    "for root_dir in root_dirs:\n",
    "    results[root_dir] = {\n",
    "        'first_size': None,\n",
    "        'inconsistent_images': []\n",
    "    }\n",
    "    \n",
    "    current_result = results[root_dir]\n",
    "    \n",
    "    print(f\"\\n{root_dir.upper()} directory check start\")\n",
    "    \n",
    "    try:\n",
    "        dataset = datasets.ImageFolder(root_dir, transform=None)\n",
    "        image_paths_and_labels = dataset.samples\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  No '{root_dir}' directory.\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"  Error loading data from '{root_dir}': {e}\")\n",
    "        continue\n",
    "        \n",
    "    if not image_paths_and_labels:\n",
    "        print(f\"  No images found in '{root_dir}'.\")\n",
    "        continue\n",
    "\n",
    "    for image_path, _ in image_paths_and_labels:\n",
    "        try:\n",
    "            with Image.open(image_path) as img:\n",
    "                current_size = img.size # (width, height)\n",
    "                \n",
    "                if current_result['first_size'] is None:\n",
    "                    current_result['first_size'] = current_size\n",
    "                \n",
    "                elif current_size != current_result['first_size']:\n",
    "                    current_result['inconsistent_images'].append({\n",
    "                        'path': image_path,\n",
    "                        'actual_size': current_size\n",
    "                    })\n",
    "                    \n",
    "        except IOError:\n",
    "            print(f\"  Can't open '{image_path}'.\")\n",
    "\n",
    "for root_dir in root_dirs:\n",
    "    result = results.get(root_dir)\n",
    "    if not result:\n",
    "        continue\n",
    "        \n",
    "    first_size = result['first_size']\n",
    "    inconsistent_images = result['inconsistent_images']\n",
    "    inconsistent_count = len(inconsistent_images)\n",
    "    \n",
    "    print(f\"\\n### {root_dir.upper()} directory\")\n",
    "    \n",
    "    if first_size is None and inconsistent_count == 0:\n",
    "        print(\"  [Error] No data.\")\n",
    "    elif inconsistent_count == 0:\n",
    "        print(f\"  Sizes of all data are {first_size}.\")\n",
    "    else:\n",
    "        for item in inconsistent_images:\n",
    "            print(f\"  File: {item['path']} | Size: {item['actual_size']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5758a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- A. 224x224 PCA value ---\n",
      "POC_EIGVALS_224 = torch.tensor([ 3290.864258, 1239.206299, 538.111511 ])\n",
      "POC_EIGVECS_224 = torch.tensor([\n",
      "    [0.4459, 0.7635, 0.4671],\n",
      "    [0.8872, -0.4461, -0.1177],\n",
      "    [-0.1185, -0.4669, 0.8763],\n",
      "])\n",
      "\n",
      "--- B. 256x256 PCA value ---\n",
      "POC_EIGVALS_256 = torch.tensor([ 3126.742920, 1230.723022, 530.931519 ])\n",
      "POC_EIGVECS_256 = torch.tensor([\n",
      "    [0.4332, 0.7737, 0.4623],\n",
      "    [0.8945, -0.4318, -0.1156],\n",
      "    [-0.1102, -0.4637, 0.8791],\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "# PCA for color augmentation\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "data_dir = 'train'\n",
    "\n",
    "def calculate_pca_for_rgb(data_dir, img_size):\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor() # (0~1)\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"  No \\'{data_dir}\\' directory.\")\n",
    "        return None, None\n",
    "    \n",
    "    rgb_pixels = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        img_tensor, _ = dataset[i]\n",
    "        \n",
    "        # (C, H, W) -> (H*W, 3) (range: 0~255)\n",
    "        img_np = (img_tensor.numpy() * 255).astype(np.uint8)\n",
    "        pixels = img_np.transpose(1, 2, 0).reshape(-1, 3) \n",
    "        rgb_pixels.append(pixels)\n",
    "\n",
    "    all_rgb_pixels = np.concatenate(rgb_pixels, axis=0)\n",
    "    \n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(all_rgb_pixels)\n",
    "    \n",
    "    eigenvectors = pca.components_\n",
    "    eigenvalues = pca.explained_variance_\n",
    "\n",
    "    eigenvalues_tensor = torch.from_numpy(eigenvalues).float()\n",
    "    eigenvectors_tensor = torch.from_numpy(eigenvectors).float()\n",
    "    \n",
    "    return eigenvalues_tensor, eigenvectors_tensor\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # 224x224 (for resize)\n",
    "    eigvals_224, eigvecs_224 = calculate_pca_for_rgb(data_dir, 224)\n",
    "    \n",
    "    # 256x256 (for crop)\n",
    "    eigvals_256, eigvecs_256 = calculate_pca_for_rgb(data_dir, 256)\n",
    "\n",
    "\n",
    "    if eigvals_224 is not None:\n",
    "        print(\"\\n--- A. 224x224 PCA value ---\")\n",
    "        print(\"POC_EIGVALS_224 = torch.tensor([\", ', '.join(f\"{v:.6f}\" for v in eigvals_224), \"])\")\n",
    "        print(\"POC_EIGVECS_224 = torch.tensor([\")\n",
    "        for i in range(3):\n",
    "            print(f\"    [{eigvecs_224[i, 0]:.4f}, {eigvecs_224[i, 1]:.4f}, {eigvecs_224[i, 2]:.4f}],\")\n",
    "        print(\"])\")\n",
    "\n",
    "    if eigvals_256 is not None:\n",
    "        print(\"\\n--- B. 256x256 PCA value ---\")\n",
    "        print(\"POC_EIGVALS_256 = torch.tensor([\", ', '.join(f\"{v:.6f}\" for v in eigvals_256), \"])\")\n",
    "        print(\"POC_EIGVECS_256 = torch.tensor([\")\n",
    "        for i in range(3):\n",
    "            print(f\"    [{eigvecs_256[i, 0]:.4f}, {eigvecs_256[i, 1]:.4f}, {eigvecs_256[i, 2]:.4f}],\")\n",
    "        print(\"])\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
